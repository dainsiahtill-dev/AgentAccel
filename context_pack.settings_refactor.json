{
  "version": 1,
  "task": "Refactor hotspot src/frontend/src/app/components/SettingsModal.tsx by extracting provider list preparation helpers with no behavior change",
  "generated_at": "2026-02-10T18:48:06.730656+00:00",
  "budget": {
    "max_chars": 24000,
    "max_snippets": 60,
    "top_n_files": 12
  },
  "top_files": [
    {
      "path": "src/frontend/src/app/App.tsx",
      "score": 0.866667,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 1.0
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 1.0
        },
        {
          "signal_name": "test_relevance",
          "score": 0.333333
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/app/llm/providers/codex_cli_provider.py",
      "score": 0.811765,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 1.0
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.058824
        },
        {
          "signal_name": "test_relevance",
          "score": 1.0
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/app/llm/providers/gemini_cli_provider.py",
      "score": 0.811765,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 1.0
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.058824
        },
        {
          "signal_name": "test_relevance",
          "score": 1.0
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/core/harborpilot_loop/context_engine.py",
      "score": 0.8,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 1.0
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.0
        },
        {
          "signal_name": "test_relevance",
          "score": 1.0
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/app/llm/providers/provider_registry.py",
      "score": 0.796078,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 1.0
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.647059
        },
        {
          "signal_name": "test_relevance",
          "score": 0.333333
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/tests/test_enhanced_providers.py",
      "score": 0.773529,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 1.0
        },
        {
          "signal_name": "reference_proximity",
          "score": 0.941176
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.941176
        },
        {
          "signal_name": "test_relevance",
          "score": 0.0
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/scripts/loop-pm.py",
      "score": 0.761765,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 0.823529
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.117647
        },
        {
          "signal_name": "test_relevance",
          "score": 1.0
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/frontend/src/app/components/SettingsModal.tsx",
      "score": 0.744118,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact",
        "changed_file"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 0.411765
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 1.0
        },
        {
          "signal_name": "test_relevance",
          "score": 0.0
        },
        {
          "signal_name": "changed_boost",
          "score": 0.15
        }
      ]
    },
    {
      "path": "src/backend/app/utils.py",
      "score": 0.738235,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 0.823529
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.0
        },
        {
          "signal_name": "test_relevance",
          "score": 1.0
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/app/routers/llm.py",
      "score": 0.730392,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 1.0
        },
        {
          "signal_name": "reference_proximity",
          "score": 0.941176
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.058824
        },
        {
          "signal_name": "test_relevance",
          "score": 0.666667
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/app/llm/providers/minimax_provider.py",
      "score": 0.715686,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "dependency_impact",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 1.0
        },
        {
          "signal_name": "reference_proximity",
          "score": 0.882353
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.058824
        },
        {
          "signal_name": "test_relevance",
          "score": 0.666667
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    },
    {
      "path": "src/backend/core/harborpilot_loop/io_utils.py",
      "score": 0.697059,
      "reasons": [
        "symbol_match",
        "reference_proximity",
        "test_relevance"
      ],
      "signals": [
        {
          "signal_name": "symbol_match",
          "score": 0.705882
        },
        {
          "signal_name": "reference_proximity",
          "score": 1.0
        },
        {
          "signal_name": "dependency_impact",
          "score": 0.0
        },
        {
          "signal_name": "test_relevance",
          "score": 1.0
        },
        {
          "signal_name": "changed_boost",
          "score": 0.0
        }
      ]
    }
  ],
  "snippets": [
    {
      "path": "src/frontend/src/app/App.tsx",
      "start_line": 157,
      "end_line": 237,
      "symbol": "appendLiveContent",
      "reason": "symbol_or_token_focus",
      "content": "  feedback_mtime?: string | null;\n  draft_failed?: boolean | null;\n}\n\ninterface RuntimeIssue {\n  code: string;\n  title: string;\n  detail: string;\n}\n\ninterface FilePayload {\n  content: string;\n  mtime: string;\n}\n\nconst LIVE_CHANNELS = [\n  'status',\n  'dialogue',\n  'pm_report',\n  'pm_log',\n  'pm_subprocess',\n  'director_console',\n  'planner',\n  'ollama',\n  'qa',\n  'runlog',\n] as const;\n\nconst CHANNEL_TO_PATH: Record<string, string> = {\n  dialogue: '.harborpilot/runtime/DIALOGUE.jsonl',\n  pm_report: '.harborpilot/runtime/PM_REPORT.md',\n  pm_log: '.harborpilot/runtime/PM_LOG.jsonl',\n  pm_subprocess: '.harborpilot/runtime/PM_SUBPROCESS.log',\n  director_console: '.harborpilot/runtime/DIRECTOR_SUBPROCESS.log',\n  planner: '.harborpilot/runtime/PLANNER_RESPONSE.md',\n  ollama: '.harborpilot/runtime/OLLAMA_RESPONSE.md',\n  qa: '.harborpilot/runtime/QA_RESPONSE.md',\n  runlog: '.harborpilot/runtime/RUNLOG.md',\n};\n\nfunction appendLiveContent(prev: string, incoming: string, maxLines = 2000) {\n  const combined = prev ? `${prev}\\n${incoming}` : incoming;\n  const lines = combined.split('\\n');\n  if (lines.length <= maxLines) {\n    return combined;\n  }\n  return lines.slice(-maxLines).join('\\n');\n}\n\nfunction normalizeDialogueEvent(raw: Record<string, unknown>): DialogueEvent | null {\n  if (!raw) return null;\n  const eventId = String(raw.event_id ?? '').trim();\n  const rawSpeakerValue = raw.speaker ?? 'System';\n  const rawSpeaker = typeof rawSpeakerValue === 'string' ? rawSpeakerValue : String(rawSpeakerValue);\n  const speaker = ['PM', 'Director', 'QA', 'Reviewer', 'System'].includes(rawSpeaker)\n    ? (rawSpeaker as DialogueEvent['speaker'])\n    : 'System';\n  const content = String(raw.text ?? raw.summary ?? raw.content ?? '').trim();\n  let timestamp = String(raw.timestamp ?? raw.ts ?? raw.time ?? '').trim();\n  if (timestamp.includes('T')) {\n    timestamp = timestamp.split('T')[1].replace('Z', '');\n  }\n  const seq = typeof raw.seq === 'number' ? raw.seq : undefined;\n  const type = typeof raw.type === 'string' ? raw.type : undefined;\n  const refs =\n    raw.refs && typeof raw.refs === 'object'\n      ? (raw.refs as DialogueEvent['refs'])\n      : undefined;\n  return {\n    seq,\n    eventId: eventId || undefined,\n    speaker,\n    type,\n    content: content || '(empty)',\n    timestamp,\n    refs,\n  };\n}\n\nfunction summarizeActionError(detail: string, maxLen = 160) {\n  const trimmed = detail.trim();"
    },
    {
      "path": "src/backend/app/llm/providers/codex_cli_provider.py",
      "start_line": 1,
      "end_line": 74,
      "symbol": "_normalize_command",
      "reason": "symbol_or_token_focus",
      "content": "from __future__ import annotations\n\nimport json\nimport os\nimport re\nimport shutil\nimport subprocess\nimport time\nimport threading\nimport queue\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\n\nfrom .base_provider import (\n    BaseProvider, ProviderInfo, HealthResult, ModelListResult,\n    InvokeResult, ValidationResult, ThinkingInfo, WorkingDirConfig\n)\nfrom ..types import estimate_usage, ModelInfo\nfrom ...utils import build_utf8_env\n\n# Try to import PTY support for real-time terminal output\ntry:\n    import pty\n    HAS_PTY = True\nexcept ImportError:\n    HAS_PTY = False\n\ntry:\n    import winpty\n    HAS_WINPTY = True\nexcept ImportError:\n    HAS_WINPTY = False\n\n\ndef _normalize_command(command: str) -> List[str]:\n    \"\"\"Normalize command for different platforms\"\"\"\n    ext = os.path.splitext(command)[1].lower()\n    if ext == \".ps1\":\n        return [\"powershell\", \"-NoProfile\", \"-ExecutionPolicy\", \"Bypass\", \"-File\", command]\n    if ext in (\".cmd\", \".bat\"):\n        return [\"cmd.exe\", \"/c\", command]\n    return [command]\n\n\ndef _truncate(text: str, limit: int) -> str:\n    \"\"\"Truncate text to specified limit with ellipsis\"\"\"\n    if not text:\n        return \"\"\n    if len(text) <= limit:\n        return text\n    return text[: max(0, limit - 3)] + \"...\"\n\n\ndef _resolve_command(command: str) -> Optional[str]:\n    \"\"\"Resolve command path\"\"\"\n    if not command:\n        return None\n    if os.path.isabs(command) or os.path.exists(command):\n        return command\n    return shutil.which(command)\n\n\ndef _supports_reasoning_effort(model: str) -> bool:\n    \"\"\"Heuristic check for models that accept reasoning.effort config.\"\"\"\n    if not model:\n        return False\n    lowered = model.strip().lower()\n    if lowered.startswith((\"gpt-\", \"o1\", \"o3\", \"o4\")):\n        return True\n    if \"codex\" in lowered:\n        return True\n    return False\n\n\ndef _build_codex_exec_args(model: str, config: Dict[str, Any]) -> List[str]:"
    },
    {
      "path": "src/backend/app/llm/providers/gemini_cli_provider.py",
      "start_line": 1,
      "end_line": 59,
      "symbol": "GeminiCLIProvider",
      "reason": "symbol_or_token_focus",
      "content": "from __future__ import annotations\n\nimport os\nimport shutil\nimport subprocess\nimport time\nimport json\nimport re\nfrom typing import Any, Dict, List, Optional, Tuple\n\nfrom ...utils import build_utf8_env\nfrom ..types import HealthResult, InvokeResult, ModelInfo, ModelListResult, estimate_usage\nfrom .base_provider import (\n    BaseProvider, ProviderInfo, ValidationResult, ThinkingInfo, \n    WorkingDirConfig\n)\n\n\nclass GeminiCLIProvider(BaseProvider):\n    \"\"\"Gemini CLI provider with thinking extraction\"\"\"\n    \n    @classmethod\n    def get_provider_info(cls) -> ProviderInfo:\n        return ProviderInfo(\n            name=\"Gemini CLI Provider\",\n            type=\"gemini_cli\",\n            description=\"Google Gemini command-line interface provider\",\n            version=\"1.0.0\",\n            author=\"HarborPilot Team\",\n            documentation_url=\"https://ai.google.dev/cli\",\n            supported_features=[\n                \"thinking_extraction\",\n                \"working_directory\",\n                \"health_check\",\n                \"streaming\",\n                \"autonomous_file_operations\",\n                \"api_key_auth\"\n            ],\n            cost_class=\"METERED\",\n            provider_category=\"AGENT\",\n            autonomous_file_access=True,\n            requires_file_interfaces=False,\n            model_listing_method=\"TUI\"\n        )\n    \n    @classmethod\n    def get_default_config(cls) -> Dict[str, Any]:\n        return {\n            \"command\": \"gemini\",\n            \"args\": [\"chat\", \"--model\", \"{model}\", \"--prompt\", \"{prompt}\"],\n            \"cli_mode\": \"headless\",\n            \"env\": {\n                \"GOOGLE_API_KEY\": \"\",\n                \"GOOGLE_GENAI_USE_VERTEXAI\": \"false\",\n                \"GOOGLE_GENAI_API_KEY\": \"\"\n            },\n            \"working_dir\": \"\",\n            \"timeout\": 60,\n            \"health_args\": [\"version\"],"
    },
    {
      "path": "src/backend/core/harborpilot_loop/context_engine.py",
      "start_line": 1,
      "end_line": 66,
      "symbol": "_utc_now",
      "reason": "symbol_or_token_focus",
      "content": "from __future__ import annotations\n\nimport hashlib\nimport json\nimport os\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime, timezone\nfrom typing import Any, Dict, List, Optional, Tuple\nfrom uuid import uuid4\n\nfrom pydantic import BaseModel, Field\n\nfrom io_utils import (\n    build_cache_root,\n    emit_event,\n    read_file_safe,\n    resolve_artifact_path,\n    resolve_ramdisk_root,\n    resolve_run_dir,\n    write_text_atomic,\n)\nfrom anthropomorphic.memory_store import MemoryStore, _has_refs\nfrom repo_map import build_repo_map\n\n\ndef _utc_now() -> datetime:\n    return datetime.now(timezone.utc)\n\n\ndef _hash_text(text: str) -> str:\n    hasher = hashlib.sha1()\n    hasher.update((text or \"\").encode(\"utf-8\", errors=\"ignore\"))\n    return hasher.hexdigest()\n\n\ndef _estimate_tokens(text: str) -> int:\n    if not text:\n        return 0\n    return max(1, int(len(text) / 4))\n\n\ndef _safe_json(obj: Any) -> str:\n    try:\n        return json.dumps(obj, ensure_ascii=False)\n    except Exception:\n        return \"{}\"\n\n\ndef _read_tail_lines(path: str, max_lines: int = 200) -> List[str]:\n    if not path or not os.path.exists(path):\n        return []\n    try:\n        with open(path, \"rb\") as handle:\n            handle.seek(0, os.SEEK_END)\n            pos = handle.tell()\n            block = 4096\n            data = b\"\"\n            while pos > 0 and data.count(b\"\\n\") <= max_lines:\n                read_size = block if pos >= block else pos\n                pos -= read_size\n                handle.seek(pos)\n                data = handle.read(read_size) + data\n    except Exception:\n        return []\n    text = data.decode(\"utf-8\", errors=\"ignore\")\n    lines = text.splitlines()"
    },
    {
      "path": "src/backend/app/llm/providers/provider_registry.py",
      "start_line": 1,
      "end_line": 60,
      "symbol": "ProviderManager",
      "reason": "symbol_or_token_focus",
      "content": "from __future__ import annotations\n\nfrom typing import Dict, List, Optional, Type, Any\nimport importlib\nimport inspect\nfrom pathlib import Path\n\nfrom .base_provider import BaseProvider, ProviderInfo\nfrom .codex_cli_provider import CodexCLIProvider\nfrom .codex_sdk_provider import CodexSDKProvider\nfrom .ollama_provider import OllamaProvider\nfrom .openai_compat_provider import OpenAICompatProvider\nfrom .anthropic_compat_provider import AnthropicCompatProvider\nfrom .gemini_cli_provider import GeminiCLIProvider\nfrom .minimax_provider import MiniMaxProvider\nfrom .gemini_api_provider import GeminiAPIProvider\nfrom .kimi_provider import KimiProvider\n\n\nclass ProviderManager:\n    \"\"\"Manages provider registration, discovery, and instantiation\"\"\"\n    \n    def __init__(self):\n        self._provider_classes: Dict[str, Type[BaseProvider]] = {}\n        self._provider_instances: Dict[str, BaseProvider] = {}\n        self._register_default_providers()\n    \n    def _register_default_providers(self) -> None:\n        \"\"\"Register all default providers\"\"\"\n        # Register enhanced providers\n        self.register_provider(\"codex_sdk\", CodexSDKProvider)\n        self.register_provider(\"codex_cli\", CodexCLIProvider)  # Use proper Codex CLI provider\n        self.register_provider(\"gemini_cli\", GeminiCLIProvider)\n        self.register_provider(\"minimax\", MiniMaxProvider)\n        self.register_provider(\"kimi\", KimiProvider)\n        self.register_provider(\"gemini_api\", GeminiAPIProvider)\n        self.register_provider(\"ollama\", OllamaProvider)\n        self.register_provider(\"openai_compat\", OpenAICompatProvider)\n        self.register_provider(\"anthropic_compat\", AnthropicCompatProvider)\n        \n        # Legacy function-based providers remain available for backward compatibility.\n    \n    def register_provider(self, provider_type: str, provider_class: Type[BaseProvider]) -> None:\n        \"\"\"Register a provider class\"\"\"\n        if not issubclass(provider_class, BaseProvider):\n            raise ValueError(f\"Provider class {provider_class} must inherit from BaseProvider\")\n        \n        self._provider_classes[provider_type] = provider_class\n        \n        # Also register with the global registry for backward compatibility\n        from .base_provider import provider_registry\n        provider_registry.register(provider_type, provider_class)\n    \n    def get_provider_class(self, provider_type: str) -> Optional[Type[BaseProvider]]:\n        \"\"\"Get a provider class by type\"\"\"\n        resolved = \"codex_cli\" if provider_type == \"cli\" else provider_type\n        return self._provider_classes.get(resolved)\n    \n    def get_provider_instance(self, provider_type: str) -> Optional[BaseProvider]:\n        \"\"\"Get or create a provider instance\"\"\""
    },
    {
      "path": "src/backend/tests/test_enhanced_providers.py",
      "start_line": 1,
      "end_line": 57,
      "symbol": "TestCodexCLIProvider",
      "reason": "symbol_or_token_focus",
      "content": "\"\"\"\nTests for enhanced LLM providers with thinking extraction and CLI behavior\n\"\"\"\n\nimport pytest\nimport sys\nfrom app.llm.providers.codex_cli_provider import CodexCLIProvider\nfrom app.llm.providers.gemini_cli_provider import GeminiCLIProvider\nfrom app.llm.providers.minimax_provider import MiniMaxProvider\nfrom app.llm.providers.gemini_api_provider import GeminiAPIProvider\nfrom app.llm.providers.openai_compat_provider import OpenAICompatProvider\nfrom app.llm.providers.anthropic_compat_provider import AnthropicCompatProvider\nfrom app.llm.providers.ollama_provider import OllamaProvider\nfrom app.llm.providers.provider_registry import provider_manager\n\n\nclass TestCodexCLIProvider:\n    \"\"\"Test Codex CLI Provider\"\"\"\n    \n    def test_provider_info(self):\n        \"\"\"Test provider information\"\"\"\n        info = CodexCLIProvider.get_provider_info()\n        assert info.name == \"Codex CLI Provider\"\n        assert info.type == \"codex_cli\"\n        assert info.provider_category == \"AGENT\"\n        assert info.autonomous_file_access is True\n        assert info.model_listing_method == \"TUI\"\n        assert \"thinking_extraction\" in info.supported_features\n        assert info.cost_class == \"FIXED\"\n    \n    def test_default_config(self):\n        \"\"\"Test default configuration\"\"\"\n        config = CodexCLIProvider.get_default_config()\n        assert \"command\" in config\n        assert \"codex_exec\" in config\n        assert \"manual_models\" in config\n        assert config[\"codex_exec\"][\"json\"] is True\n        assert config[\"codex_exec\"][\"sandbox\"] == \"read-only\"\n        assert config[\"cli_mode\"] == \"headless\"\n    \n    def test_validate_config(self):\n        \"\"\"Test configuration validation\"\"\"\n        # Valid config\n        valid_config = {\n            \"command\": \"codex\",\n            \"codex_exec\": {\n                \"json\": True,\n                \"sandbox\": \"read-only\"\n            },\n            \"timeout\": 60\n        }\n        result = CodexCLIProvider.validate_config(valid_config)\n        assert result.valid is True\n        assert len(result.errors) == 0\n        \n        # Invalid config\n        invalid_config = {"
    },
    {
      "path": "src/backend/scripts/loop-pm.py",
      "start_line": 1,
      "end_line": 73,
      "symbol": "enforce_utf8",
      "reason": "symbol_or_token_focus",
      "content": "import argparse\nimport hashlib\nimport json\nimport os\nimport subprocess\nimport sys\nimport time\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional, Tuple\n\ntry:\n    from director_result_matcher import (\n        match_director_result as _match_director_result,\n        match_director_result_any as _match_director_result_any,\n        match_director_result_mode as _match_director_result_mode,\n        normalize_match_mode as _normalize_match_mode,\n        result_timestamp_epoch as _result_timestamp_epoch,\n        wait_for_director_result as _wait_for_director_result,\n        wait_for_director_result_mode as _wait_for_director_result_mode,\n    )\nexcept ModuleNotFoundError:\n    from src.backend.scripts.director_result_matcher import (\n        match_director_result as _match_director_result,\n        match_director_result_any as _match_director_result_any,\n        match_director_result_mode as _match_director_result_mode,\n        normalize_match_mode as _normalize_match_mode,\n        result_timestamp_epoch as _result_timestamp_epoch,\n        wait_for_director_result as _wait_for_director_result,\n        wait_for_director_result_mode as _wait_for_director_result_mode,\n    )\n\n\ndef enforce_utf8() -> None:\n    os.environ.setdefault(\"PYTHONUTF8\", \"1\")\n    os.environ.setdefault(\"PYTHONIOENCODING\", \"utf-8\")\n    os.environ.setdefault(\"LANG\", \"en_US.UTF-8\")\n    os.environ.setdefault(\"LC_ALL\", \"en_US.UTF-8\")\n    try:\n        sys.stdout.reconfigure(encoding=\"utf-8\")\n    except Exception:\n        pass\n    try:\n        sys.stderr.reconfigure(encoding=\"utf-8\")\n    except Exception:\n        pass\n\n\nenforce_utf8()\n\n\ndef build_utf8_env(extra: Optional[Dict[str, str]] = None) -> Dict[str, str]:\n    env = os.environ.copy()\n    env.setdefault(\"PYTHONUTF8\", \"1\")\n    env.setdefault(\"PYTHONIOENCODING\", \"utf-8\")\n    env.setdefault(\"LANG\", \"en_US.UTF-8\")\n    env.setdefault(\"LC_ALL\", \"en_US.UTF-8\")\n    if extra:\n        env.update(extra)\n    return env\n\n\nSCRIPT_DIR = os.path.dirname(__file__)\nPROJECT_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, \"..\"))\nPROMPT_PROFILE_ENV = \"HARBORPILOT_PROMPT_PROFILE\"\nDEFAULT_DIRECTOR_SUBPROCESS_LOG = \".harborpilot/runtime/DIRECTOR_SUBPROCESS.log\"\nDEFAULT_DIRECTOR_STATUS = \".harborpilot/runtime/DIRECTOR_STATUS.json\"\nAGENTS_DRAFT_REL = \".harborpilot/runtime/AGENTS.generated.md\"\nAGENTS_FEEDBACK_REL = \".harborpilot/runtime/AGENTS.feedback.md\"\nREQUIRED_MODULE_FILES = (\n    \"decision.py\",\n    \"codex_utils.py\",\n    \"io_utils.py\",\n    \"policy.py\","
    },
    {
      "path": "src/frontend/src/app/components/SettingsModal.tsx",
      "start_line": 81,
      "end_line": 161,
      "symbol": "SettingsModal",
      "reason": "symbol_or_token_focus",
      "content": "    interval?: number;\n    timeout?: number;\n    refresh_interval?: number;\n    auto_refresh?: boolean;\n    show_memory?: boolean;\n    io_fsync_mode?: string;\n    memory_refs_mode?: string;\n    ramdisk_root?: string;\n    json_log_path?: string;\n    pm_show_output?: boolean;\n    pm_runs_director?: boolean;\n    pm_director_show_output?: boolean;\n    pm_director_timeout?: number;\n    pm_director_iterations?: number;\n    pm_director_match_mode?: string;\n    pm_max_failures?: number;\n    pm_max_blocked?: number;\n    pm_max_same?: number;\n    director_iterations?: number;\n    director_forever?: boolean;\n    director_show_output?: boolean;\n    qa_enabled?: boolean;\n    debug_tracing?: boolean;\n  }) => Promise<void>;\n}\n\ninterface ProviderValidationResult {\n  valid: boolean;\n  errors?: string[];\n  warnings?: string[];\n  normalized_config?: Record<string, unknown> | null;\n}\n\nconst ROLE_META: Record<string, { label: string; color: string; badge: string }> = {\n  pm: { label: 'PM', color: 'text-cyan-300', badge: 'bg-cyan-500/20 text-cyan-200 border-cyan-500/30' },\n  director: { label: 'Director', color: 'text-purple-300', badge: 'bg-purple-500/20 text-purple-200 border-purple-500/30' },\n  qa: { label: 'QA', color: 'text-blue-200', badge: 'bg-blue-500/20 text-blue-200 border-blue-500/30' },\n  docs: { label: 'Docs', color: 'text-emerald-300', badge: 'bg-emerald-500/20 text-emerald-200 border-emerald-500/30' },\n};\n\nexport function SettingsModal({ isOpen, onClose, settings, onSave }: SettingsModalProps) {\n  const defaultProfile = 'demo_ming_armada';\n  const [promptProfile, setPromptProfile] = useState(defaultProfile);\n  const [refreshInterval, setRefreshInterval] = useState(3);\n  const [autoRefresh, setAutoRefresh] = useState(true);\n  const [pmInterval, setPmInterval] = useState(20);\n  const [pmTimeout, setPmTimeout] = useState(0);\n  const [pmRunsDirector, setPmRunsDirector] = useState(true);\n  const [pmDirectorShowOutput, setPmDirectorShowOutput] = useState(true);\n  const [pmDirectorTimeout, setPmDirectorTimeout] = useState(600);\n  const [pmDirectorIterations, setPmDirectorIterations] = useState(1);\n  const [pmDirectorMatchMode, setPmDirectorMatchMode] = useState('latest');\n  const [pmShowOutput, setPmShowOutput] = useState(true);\n  const [pmMaxFailures, setPmMaxFailures] = useState(5);\n  const [pmMaxBlocked, setPmMaxBlocked] = useState(5);\n  const [pmMaxSame, setPmMaxSame] = useState(3);\n  const [directorIterations, setDirectorIterations] = useState(1);\n  const [directorForever, setDirectorForever] = useState(false);\n  const [directorShowOutput, setDirectorShowOutput] = useState(true);\n  const [qaEnabled, setQaEnabled] = useState(true);\n  const [ramdiskRoot, setRamdiskRoot] = useState('');\n  const [jsonLogPath, setJsonLogPath] = useState('.harborpilot/runtime/PM_LOG.jsonl');\n  const [showMemory, setShowMemory] = useState(false);\n  const [debugTracing, setDebugTracing] = useState(false);\n  const [ioFsyncMode, setIoFsyncMode] = useState<'strict' | 'relaxed'>('strict');\n  const [memoryRefsMode, setMemoryRefsMode] = useState<'strict' | 'soft' | 'off'>('soft');\n  const [activeTab, setActiveTab] = useState('general');\n  const [saving, setSaving] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n  const [llmConfig, setLLMConfig] = useState<LLMConfig | null>(null);\n  const [llmStatus, setLLMStatus] = useState<LLMStatus | null>(null);\n  const [llmLoading, setLlmLoading] = useState(false);\n  const [llmSaving, setLlmSaving] = useState(false);\n  const [llmError, setLlmError] = useState<string | null>(null);\n  const [llmTesting, setLlmTesting] = useState<Record<string, boolean>>({});\n  const [providerModels, setProviderModels] = useState<Record<string, { supported: boolean; models: string[] }>>({});\n  const [providerKeyDrafts, setProviderKeyDrafts] = useState<Record<string, string>>({});\n  const [providerKeyStatus, setProviderKeyStatus] = useState<Record<string, string>>({});\n  const [reportDrawer, setReportDrawer] = useState<{ open: boolean; data: unknown | null }>({ open: false, data: null });\n  const [testSuites, setTestSuites] = useState({ connectivity: true, response: true, qualification: false });\n  const [testLevel, setTestLevel] = useState<'quick' | 'full'>('quick');"
    },
    {
      "path": "src/backend/app/utils.py",
      "start_line": 1,
      "end_line": 60,
      "symbol": "enforce_utf8",
      "reason": "symbol_or_token_focus",
      "content": "import os\nimport sys\nimport json\nimport hashlib\nimport shutil\nfrom datetime import datetime, timezone\nfrom typing import List, Dict, Any, Optional, Tuple\nfrom fastapi import HTTPException\nfrom .config import (\n    Settings,\n    ARTIFACT_ROOT,\n    ARTIFACT_NAMESPACE,\n    LEGACY_ARTIFACT_ROOT,\n    LEGACY_ARTIFACT_NAMESPACE,\n    STATE_TO_RAMDISK_ENV,\n    LOOP_MODULE_DIR,\n    WORKSPACE_STATUS_REL\n)\n\ndef enforce_utf8() -> None:\n    os.environ.setdefault(\"PYTHONUTF8\", \"1\")\n    os.environ.setdefault(\"PYTHONIOENCODING\", \"utf-8\")\n    os.environ.setdefault(\"LANG\", \"en_US.UTF-8\")\n    os.environ.setdefault(\"LC_ALL\", \"en_US.UTF-8\")\n    try:\n        sys.stdout.reconfigure(encoding=\"utf-8\")\n    except Exception:\n        pass\n    try:\n        sys.stderr.reconfigure(encoding=\"utf-8\")\n    except Exception:\n        pass\n\ndef build_utf8_env(extra: Optional[Dict[str, str]] = None) -> Dict[str, str]:\n    env = os.environ.copy()\n    env.setdefault(\"PYTHONUTF8\", \"1\")\n    env.setdefault(\"PYTHONIOENCODING\", \"utf-8\")\n    env.setdefault(\"LANG\", \"en_US.UTF-8\")\n    env.setdefault(\"LC_ALL\", \"en_US.UTF-8\")\n    if extra:\n        env.update(extra)\n    return env\n\ndef ensure_loop_modules() -> None:\n    if os.path.isdir(LOOP_MODULE_DIR) and LOOP_MODULE_DIR not in sys.path:\n        sys.path.insert(0, LOOP_MODULE_DIR)\n\ndef normalize_ramdisk_root(value: str) -> str:\n    raw = (value or \"\").strip()\n    if not raw:\n        return \"\"\n    if not os.path.isabs(raw):\n        return \"\"\n    if len(raw) == 2 and raw[1] == \":\":\n        raw = raw + \"\\\\\"\n    raw = os.path.abspath(raw)\n    raw = raw.rstrip(\"\\\\/\")\n    if len(raw) == 2 and raw[1] == \":\":\n        raw = raw + \"\\\\\"\n    return raw"
    },
    {
      "path": "src/backend/app/routers/llm.py",
      "start_line": 8,
      "end_line": 88,
      "symbol": "get_state",
      "reason": "symbol_or_token_focus",
      "content": "from typing import Any, Dict, Optional\nfrom uuid import uuid4\n\nfrom fastapi import APIRouter, Depends, HTTPException, Request\nfrom fastapi.responses import StreamingResponse\nfrom pydantic import BaseModel, Field, field_validator\n\nfrom ..config import Settings\nfrom ..state import AppState, Auth\nfrom ..utils import build_cache_root, resolve_artifact_path\nfrom ..services.llm_tests import run_llm_tests, load_llm_test_index, reconcile_llm_test_index\nfrom ..services.llm_tests import run_llm_tests_streaming\nfrom ..services.interactive_interview import (\n    run_interactive_interview_question,\n    save_interactive_interview_report,\n)\nfrom ..services.interactive_interview_streaming import (\n    run_interactive_interview_streaming,\n    cancel_interactive_interview_stream,\n)\nfrom ..llm import config as llm_config\nfrom ..llm.providers import (\n    ollama_health,\n    ollama_list_models,\n    openai_health,\n    openai_list_models,\n    anthropic_health,\n    anthropic_list_models,\n    # New enhanced providers\n    provider_manager,\n)\nfrom ..utils import save_persisted_settings\nfrom ..services.interactive_interview import (\n    load_interview_history_summary,\n)\n\n\nrouter = APIRouter()\n\n\ndef get_state(request: Request) -> AppState:\n    return request.app.state.app_state\n\n\ndef require_auth(request: Request):\n    auth: Auth = request.app.state.auth\n    if not auth.check(request.headers.get(\"authorization\", \"\")):\n        raise HTTPException(status_code=401, detail=\"unauthorized\")\n\n\nclass LlmTestPayload(BaseModel):\n    role: Optional[str] = None\n    provider_id: Optional[str] = None\n    model: Optional[str] = None\n    suites: Optional[list[str]] = None\n    test_level: str = \"quick\"\n    evaluation_mode: Optional[str] = None\n    api_key: Optional[str] = None\n    headers: Optional[Dict[str, str]] = None\n    env_overrides: Optional[Dict[str, str]] = None\n    prompt_override: Optional[str] = None\n    # Connectivity-only fields (Scheme B): allow bypassing config loading\n    provider_type: Optional[str] = None\n    base_url: Optional[str] = None\n    api_path: Optional[str] = None\n    timeout: Optional[int] = None\n\n\nclass ProviderActionPayload(BaseModel):\n    api_key: Optional[str] = None\n    headers: Optional[Dict[str, str]] = None\n\n\nclass InterviewAskPayload(BaseModel):\n    role: str\n    provider_id: str\n    model: str\n    question: str\n    context: Optional[list[Dict[str, Any]]] = None\n    expects_thinking: Optional[bool] = None\n    criteria: Optional[list[str]] = None"
    }
  ],
  "verify_plan": {
    "target_tests": [
      "agent-accel/tests/integration/test_cli_e2e.py",
      "src/backend/tests/test_codex_cli_utils.py",
      "src/backend/tests/test_repo_map_provider.py",
      "tests/test_codex_utils.py",
      "src/backend/tests/test_minimax_streaming.py",
      "src/backend/tests/test_llm_phase0_regression.py",
      "src/backend/tests/test_llm_test_index_reconcile.py",
      "tests/test_decision_utils.py",
      "tests/test_director_exec_utils.py",
      "tests/test_io_utils_core.py",
      "tests/test_io_utils_jsonl.py",
      "tests/test_loop_pm_utils.py",
      "tests/test_ollama_utils.py",
      "tests/test_shared_utils.py",
      "agent-accel/tests/unit/test_index_and_context.py",
      "src/backend/tests/test_context_engine.py",
      "tests/test_plan_act_context.py",
      "tests/test_tools_repo_io.py",
      "tests/functional/test_pm_loop.py",
      "tests/test_loop_director_required_evidence.py"
    ],
    "target_checks": [
      "npm run typecheck"
    ]
  },
  "meta": {
    "task_tokens": [
      "refactor",
      "hotspot",
      "src",
      "frontend",
      "app",
      "components",
      "settingsmodal",
      "tsx",
      "by",
      "extracting",
      "provider",
      "list",
      "preparation",
      "helpers",
      "no",
      "behavior",
      "change"
    ],
    "changed_files": [
      "src/frontend/src/app/components/SettingsModal.tsx"
    ],
    "drift_reason": ""
  }
}
